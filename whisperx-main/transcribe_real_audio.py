import torch
import warnings
import sys
import os
from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline

# ç¦ç”¨è­¦å‘Š
warnings.filterwarnings("ignore")

def transcribe_audio_file(audio_path):
    """è½¬å½•çœŸå®éŸ³é¢‘æ–‡ä»¶"""
    
    if not os.path.exists(audio_path):
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°éŸ³é¢‘æ–‡ä»¶ {audio_path}")
        return None
    
    print("ğŸ¤ WhisperX å®é™…éŸ³é¢‘è½¬å½•")
    print("=" * 60)
    print(f"ğŸ“ éŸ³é¢‘æ–‡ä»¶: {audio_path}")
    
    # è®¾å¤‡é…ç½®
    device = "cuda:0" if torch.cuda.is_available() else "cpu"
    torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32
    model_id = "openai/whisper-large-v3-turbo"
    
    print(f"ğŸ“± è®¾å¤‡: {device}")
    print(f"ğŸ”§ æ¨¡å‹: {model_id}")
    
    # åŠ è½½æ¨¡å‹
    print("â³ æ­£åœ¨åŠ è½½æ¨¡å‹...")
    model = AutoModelForSpeechSeq2Seq.from_pretrained(
        model_id, 
        torch_dtype=torch_dtype, 
        low_cpu_mem_usage=True, 
        use_safetensors=True
    )
    model.to(device)
    
    processor = AutoProcessor.from_pretrained(model_id)
    
    # åˆ›å»ºç®¡é“
    pipe = pipeline(
        "automatic-speech-recognition",
        model=model,
        tokenizer=processor.tokenizer,
        feature_extractor=processor.feature_extractor,
        torch_dtype=torch_dtype,
        device=device,
    )
    
    print("ğŸµ å¼€å§‹è½¬å½•...")
    
    # è½¬å½•éŸ³é¢‘æ–‡ä»¶
    result = pipe(
        audio_path,
        generate_kwargs={"task": "transcribe"},  # ä½¿ç”¨ transcribe è€Œä¸æ˜¯ translate
        return_timestamps=True
    )
    
    print("\n" + "=" * 60)
    print("ğŸ“ è½¬å½•ç»“æœ:")
    print("=" * 60)
    print(result["text"])
    
    # å¦‚æœæœ‰æ—¶é—´æˆ³ä¿¡æ¯ï¼Œæ˜¾ç¤ºåˆ†æ®µç»“æœ
    if "chunks" in result and result["chunks"]:
        print("\n" + "=" * 60)
        print("â° æ—¶é—´æˆ³åˆ†æ®µ:")
        print("=" * 60)
        for i, chunk in enumerate(result["chunks"], 1):
            start_time = chunk['timestamp'][0] if chunk['timestamp'][0] is not None else 0
            end_time = chunk['timestamp'][1] if chunk['timestamp'][1] is not None else "æœªçŸ¥"
            print(f"[{i:2d}] {start_time:6.2f}s - {end_time:>6}s: {chunk['text'].strip()}")
    
    print("\nâœ… è½¬å½•å®Œæˆ!")
    return result["text"]

if __name__ == "__main__":
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) != 2:
        print("ä½¿ç”¨æ–¹æ³•: python transcribe_real_audio.py <éŸ³é¢‘æ–‡ä»¶è·¯å¾„>")
        print("æ”¯æŒçš„æ ¼å¼: .wav, .mp3, .flac, .m4a, .ogg ç­‰")
        print("ç¤ºä¾‹: python transcribe_real_audio.py uploads/my_audio.wav")
        sys.exit(1)
    
    audio_file = sys.argv[1]
    transcribe_audio_file(audio_file)